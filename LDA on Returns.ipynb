{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#0071BD;color:white;text-align:center;padding-top:0.8em;padding-bottom: 0.8em\">\n",
    "  LDA on Returns\n",
    "</h1>\n",
    "\n",
    "This notebook illustrates the core ideas of Latent Dirichlet Allocation on a very minimal corpus. After you have worked through this notebook, you should have understood:\n",
    "  * A __corpus__ consists of a list of documents.\n",
    "  * The __vocabulary__ consists of the union of words that we consider relevant in the documents.\n",
    "  * Each document is represented by the __word counts__ of the words in the vocabulary.\n",
    "  * A __topic__ is a probability distribution over the vocabulary.\n",
    "  * The __topic distribution__ gives us the share that each topic has on a given document.\n",
    "  * Topic distribution times topics is an approximation of the word counts.\n",
    "  \n",
    "<p style=\"background-color:#66A5D1;padding-top:0.2em;padding-bottom: 0.2em\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments in this notebook are meant as invitations to explore alternatives.\n",
    "# On the first read, you should just ignore all the comments. On a second read\n",
    "# you might want to add more sentences to the corpus (see cells below).\n",
    "# So if this is your first read, you should start ignoring comments now.\n",
    "\n",
    "# If you enlarge the corpus, you might want to enlarge the width of the notebook\n",
    "# on the screen, to see the tables without line breaks. The two lines below make\n",
    "# the cells as wide as possible:\n",
    "\n",
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print1d(template, values):\n",
    "    for value in values: print(template.format(value), end = '')\n",
    "    print()\n",
    "    \n",
    "def print2d(template, valuess, blank = '', threshold = None):\n",
    "    for values in valuess:\n",
    "        for value in values:\n",
    "            print(template.format(value) if (threshold == None) or (value > threshold) else blank, end = '')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus definition and vocabulary creation\n",
    "\n",
    "Below you find a few sentences that obviously cover two quite distinct topics. They share a common word that has two different meanings. We consider each sentence to be a separate document. Let's see whether Latend Dirichlet Allocation is able to detect that we are looking at two different topics. Notice that the process is unsupervised, i.e. we never tell the algorithms for any document (sentence) which topic it covers. The only hint, we will give the algorithm that it should look for exactly 2 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'Investment in Deutsche Bank yields low return.',\n",
    "    'My investment may return nothing.', \n",
    "    'Federer’s return was good, his volley was not.',\n",
    "    'Return volley, return volley; tennis is boring.',\n",
    "    'Return on investment is on a ten year high.',\n",
    "#    'Tennis is for Federer!',\n",
    "#    'Deutsche Bank may be an investment bank.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORDS PER DOCUMENT:\n",
      "investment  deutsche    bank        yields      return      \n",
      "investment  return      nothing     \n",
      "federer     return      good        volley      \n",
      "return      volley      return      volley      tennis      boring      \n",
      "return      investment  year        high        \n"
     ]
    }
   ],
   "source": [
    "bags = []\n",
    "\n",
    "for document in corpus:\n",
    "    \n",
    "    tokens = re.split('[ .!,;’]', document)\n",
    "    bag    = [token.lower() for token in tokens if len(token) > 3]\n",
    "    \n",
    "#    stop_words = ['', 'in', 'my', 'may', 's', 'was', 'his', 'not', 'is', 'on', 'a', 'ten', 'for', 'be', 'an']\n",
    "#    bag        = [token.lower() for token in tokens if token.lower() not in stop_words]\n",
    "\n",
    "#    bag        = ['hi/lo' if word in {'high', 'low'} else word for word in bag]\n",
    "    \n",
    "    bags.append(bag)\n",
    "\n",
    "print('WORDS PER DOCUMENT:')\n",
    "print2d('{:12s}', bags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMBINED VOCABULARY OF ALL DOCUMENTS:\n",
      "investment  deutsche  bank  yields  return  nothing  federer  good  volley  tennis  boring  year  high  \n"
     ]
    }
   ],
   "source": [
    "vocabulary = dict.fromkeys([word for bag in bags for word in bag])\n",
    "\n",
    "# vocabulary = dict.fromkeys(['investment', 'return', 'federer', 'volley'])\n",
    "# for bag in bags: bag = [word for word in bag if word in vocabulary]\n",
    "\n",
    "words = [word for word in vocabulary.keys()]\n",
    "\n",
    "print('COMBINED VOCABULARY OF ALL DOCUMENTS:')\n",
    "print1d('{}  ', words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD COUNTS IN THE DOCUMENTS:\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "investment deutsche     bank   yields   return  nothing  federer     good   volley   tennis   boring     year     high\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "        1        1        1        1        1                                                                        \n",
      "        1                                   1        1                                                               \n",
      "                                            1                 1        1        1                                    \n",
      "                                            2                                   2        1        1                  \n",
      "        1                                   1                                                              1        1\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "        3        1        1        1        6        1        1        1        3        1        1        1        1\n"
     ]
    }
   ],
   "source": [
    "for key in vocabulary.keys(): vocabulary[key] = 0\n",
    "word_counts = np.zeros((len(corpus), len(vocabulary)), dtype=int)\n",
    "\n",
    "for d, bag in enumerate(bags):\n",
    "    for w, word in enumerate(words):\n",
    "        \n",
    "        count = bag.count(word)\n",
    "        \n",
    "        vocabulary[word] += count\n",
    "        word_counts[d, w] = count\n",
    "\n",
    "LINE = '-' + len(vocabulary) * 9 * '-'\n",
    "print('WORD COUNTS IN THE DOCUMENTS:'); print(LINE)\n",
    "print1d('{:>9}', vocabulary.keys()             ); print(LINE)\n",
    "print2d('{:9d}', word_counts,        9 * ' ', 0); print(LINE)\n",
    "print1d('{:9d}', vocabulary.values()           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "investment deutsche     bank   yields   return  nothing  federer     good   volley   tennis   boring     year     high\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "      2.4      0.5      0.5      0.5      5.5      1.5      1.5      1.5      3.5      1.5      1.5      1.5      1.5\n",
      "      1.6      1.5      1.5      1.5      1.5      0.5      0.5      0.5      0.5      0.5      0.5      0.5      0.5\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "    10.1%     2.2%     2.2%     2.2%    23.7%     6.3%     6.4%     6.4%    15.0%     6.4%     6.4%     6.4%     6.4%\n",
      "    14.0%    12.7%    12.7%    12.7%    12.6%     4.5%     4.4%     4.4%     4.3%     4.3%     4.3%     4.4%     4.4%\n",
      "----------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "n_topics = 2\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components = n_topics, learning_method='batch', max_iter=50, n_jobs = -1)\n",
    "\n",
    "lda.fit(word_counts)\n",
    "\n",
    "words_in_topics = normalize(lda.components_, norm='l1')\n",
    "\n",
    "print1d('{:>9}',   vocabulary.keys()); print(LINE)\n",
    "print2d('{:9.1f}', lda.components_  ); print(LINE)\n",
    "print2d('{:9.1%}', words_in_topics  ); print(LINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0  Topic 1  \n",
      "             89%  \n",
      "    83%           \n",
      "    89%           \n",
      "    92%           \n",
      "    87%           \n"
     ]
    }
   ],
   "source": [
    "topics_in_corpus = lda.transform(word_counts)\n",
    "\n",
    "print1d('Topic{:2d}  ', range(n_topics)               )\n",
    "print2d('{:7.0%}  ',    topics_in_corpus, 9 * ' ', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "investment deutsche     bank   yields   return  nothing  federer     good   volley   tennis   boring     year     high\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "        1        1        1        1        1                                                                        \n",
      "        1                                   1        1                                                               \n",
      "                                            1                 1        1        1                                    \n",
      "                                            2                                   2        1        1                  \n",
      "        1                                   1                                                              1        1\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "      0.7      0.6      0.6      0.6      0.7                                                                        \n",
      "                                          0.7                                 0.4                                    \n",
      "      0.4                                 0.9                                 0.6                                    \n",
      "      0.6                                 1.4      0.4      0.4      0.4      0.9      0.4      0.4      0.4      0.4\n",
      "      0.4                                 0.9                                 0.5                                    \n"
     ]
    }
   ],
   "source": [
    "words_in_corpus  = topics_in_corpus.dot(words_in_topics)\n",
    "length_in_corpus = [len(bag) for bag in bags]\n",
    "word_counts_in_corpus = np.diag(length_in_corpus).dot(words_in_corpus)\n",
    "\n",
    "print1d('{:>9}',   vocabulary.keys()                    ); print(LINE)\n",
    "print2d('{:9d}',   word_counts,           9 * ' ', 0    ); print(LINE)\n",
    "print2d('{:9.1f}', word_counts_in_corpus, 9 * ' ', 0.334)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return,volley,  investment,boring,tennis,good,federer,high,  year,nothing,yields,bank,deutsche\n",
      "investment,yields,bank,  deutsche,return,nothing,high,year,good,  federer,volley,boring,tennis\n"
     ]
    }
   ],
   "source": [
    "def topic_description(words, probabilities):\n",
    "\n",
    "    cumulated = 0\n",
    "    description = ''\n",
    "    \n",
    "    for w in np.argsort(probabilities)[::-1]:\n",
    "\n",
    "        probability = probabilities[w]\n",
    "        description += words[w]  + ','\n",
    "        \n",
    "        if (cumulated < 1/3 <= cumulated + probability) or (cumulated < 4/5 <= cumulated + probability):\n",
    "            description += '  '\n",
    "        \n",
    "        cumulated += probability\n",
    "    \n",
    "    return description.rstrip(' ').rstrip(',')\n",
    "\n",
    "descriptions = []\n",
    "\n",
    "for probabilities in words_in_topics:\n",
    "    description = topic_description(words, probabilities)\n",
    "    print(description)\n",
    "    descriptions.append(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"Investment in Deutsche Bank yields low return.\"\n",
      "-  11% return,volley,  investment,boring,tennis,good,federer,high,  year,nothing,yields,bank,deutsche\n",
      "X  89% investment,yields,bank,  deutsche,return,nothing,high,year,good,  federer,volley,boring,tennis\n",
      "\n",
      "\"My investment may return nothing.\"\n",
      "X  83% return,volley,  investment,boring,tennis,good,federer,high,  year,nothing,yields,bank,deutsche\n",
      "-  17% investment,yields,bank,  deutsche,return,nothing,high,year,good,  federer,volley,boring,tennis\n",
      "\n",
      "\"Federer’s return was good, his volley was not.\"\n",
      "X  89% return,volley,  investment,boring,tennis,good,federer,high,  year,nothing,yields,bank,deutsche\n",
      "-  11% investment,yields,bank,  deutsche,return,nothing,high,year,good,  federer,volley,boring,tennis\n",
      "\n",
      "\"Return volley, return volley; tennis is boring.\"\n",
      "X  92% return,volley,  investment,boring,tennis,good,federer,high,  year,nothing,yields,bank,deutsche\n",
      "-  8% investment,yields,bank,  deutsche,return,nothing,high,year,good,  federer,volley,boring,tennis\n",
      "\n",
      "\"Return on investment is on a ten year high.\"\n",
      "X  87% return,volley,  investment,boring,tennis,good,federer,high,  year,nothing,yields,bank,deutsche\n",
      "-  13% investment,yields,bank,  deutsche,return,nothing,high,year,good,  federer,volley,boring,tennis\n"
     ]
    }
   ],
   "source": [
    "for document, probabilities in zip(corpus, topics_in_corpus):\n",
    "\n",
    "    print('\\n\"{}\"'.format(document))\n",
    "    \n",
    "    for probability, description in zip(probabilities, descriptions):\n",
    "        print('{} {:.0%} {:}'.format('X ' if probability > 0.5 else '- ', probability, description))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img source='images/lda-on-returns-word-use-in-5-sentences.PNG'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lattice of the \"Sentence uses word\" relation\n",
    "\n",
    "Have you been suspicious of whether we actually need a probabilistic approach to distinguish these few documents? If yes, you were right. The lattice below illustrates, which document contains which word. (A document contains a word if you can reach a word starting from the document by following lines upwards.) As you see that we could just ignore \"return\" as all documents contain this word. The presence of \"investment\" or \"volley\" separates the corpus into two. The remaining words are then just specific to each of the document.\n",
    "\n",
    "<img src='images/lda-on-returns-word-use-in-5-sentences.PNG' style='width:60%'/>\n",
    "\n",
    "So, it is time to increase the corpus a bit. Scroll back to the top and include the given two more sentences. The lattice below demonstrates that an analysis based on set theory becomes hareder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lattice of the \"Sentence uses word\" relation, given two more sentences\n",
    "<img src='images/lda-on-returns-word-use-in-7-sentences.PNG' style='width:60%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "      <td colspan=\"1\" style=\"text-align:left;background-color:#0071BD;color:white\">\n",
    "        <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">\n",
    "            <img alt=\"Creative Commons License\" style=\"border-width:0;float:left;padding-right:10pt\"\n",
    "                 src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" />\n",
    "        </a>\n",
    "        &copy; D. Speicher<br/>\n",
    "        Licensed under a \n",
    "        <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\" style=\"color:white\">\n",
    "            CC BY-NC 4.0\n",
    "        </a>.\n",
    "      </td>\n",
    "      <td colspan=\"2\" style=\"text-align:left;background-color:#66A5D1\">\n",
    "          <b>Acknowledgments:</b>\n",
    "          This material was prepared within the project\n",
    "          <a href=\"http://www.b-it-center.de/b-it-programmes/teaching-material/p3ml/\" style=\"color:black\">\n",
    "              P3ML\n",
    "          </a> \n",
    "          which is funded by the Ministry of Education and Research of Germany (BMBF)\n",
    "          under grant number 01/S17064. The authors gratefully acknowledge this support.\n",
    "      </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
